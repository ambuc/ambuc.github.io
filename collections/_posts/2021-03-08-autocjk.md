---
title: Predicting CJK Character Shapes
icon: translate

layout: post
---

{% include project.html github="https://github.com/google/autocjk" %}

* TOC
{:toc}

[AutoCJK](https://github.com/google/autocjk) is a tool for generating
low-resolution predictions of uncommon CJK characters, given full-width
images of their components.

Example:

![U+20E74](https://raw.githubusercontent.com/google/autocjk/main/docs/images/0x134772.png)

| (a) | (b) | (c) | (d) | (e) |
|-----|-----|-----|-----|-----|
| source left-hand component | source right-hand component | expected composition | predicted composition | (c)/(d) difference |


> **NB:** If you already know about the Chinese language, feel free to skip 
  the *Background* section and read onwards, starting from *Work* below. Also, 
  if you already know about the Chinese language and notice something below is
  wrong, please take out an issue against
  [this page](https://github.com/ambuc/ambuc.github.io) and let me know!


## Background

### Chinese Language

The written Chinese language comprises tens of thousands of logograms (汉字; 
hànzì), each with a (non-unique) pronunciation and meaning. Hanzi are used in
many other East Asian languages, including subsets of Japanese and Korean.
Unlike some alphabets, where letters are of variable width, CJK scripts are
usually fixed-width, and character proportions and spacing exist within a
regular grid.

A subset of hanzi, known as radicals (部首; bùshǒu) can be combined to create
all other characters. The most common system of radicals is the set of 214
Kangxi radicals (康熙部首; kāngxī bùshǒu). [^1]

[^1]: Kangxi radicals were developed as an indexing system in the 1600s, but
      Chinese indexing systems are at least two millennia old.


#### Radical composition

Radicals compose in about a dozen regular ways. The new character is not
guaranteed to share pronunciation or meaning with any of its components.

* Two radicals can be composed horizontally (女 + 子 = 好) or vertically (几 + 木 =
  朵). [^2]

  [^2]: Sometimes (but not always) the left half of a character has some
        semantic hint at the meaning, and the right half of a character has
        some phonetic hint at the pronunciation.

* Three radicals can be composed horizontally (氵+ 方 + 字 = 游) or vertically (日 +
  罒 + 又 = 曼). For the horizontal case, it is common for two adjacent radicals
  to first combine into another character (方 + 字 = 斿; 氵+ 斿 = 游).

* One radical can fully surround another (囗 + 玉 = 国). 

* One radical can surround another from above, (门 + 日 = 间), from the left (匚 +
  矢 = 医), from below (凵 + 乂 = 凶), although never from the right.

* One radical can surround another from the upper-left (广 + 木 + 床), from the
  upper-right (丁 + 口 = 可), or from the lower-left (辶 + 文 = 这), although never
  from the lower-right.

* Finally, two radicals can be overlaid. Overlaid compositions are generally
  ambiguous: for example (一 + 木 = 未) and (一 + 木 = 末). (Note the widths of the
  horizontal strokes in each resultant character.)

Composition is often recursive. Examine the sequence: (乛 + 头 = 买, 十 + 买 = 卖, 
讠+ 卖 = 读). Composition depth rarely exceeds four or five layers.

#### How many Chinese characters are there?

A newspaper often contains between 2, 000 and 3, 000 unique characters. An
educated Chinese person knows around 8, 000 characters. A standard Chinese
dictionary contains around 20, 000 characters. A comprehensive Chinese
dictionary contains around 80, 000 characters.

### Chinese and Unicode

[Unicode](https://unicode.org/) is an international standard for encoding
text. Here, ‘encoding’ means associating each character as a unique number in
some range. The Unicode standard has a fixed-width encoding (called UTF-32)
which limits the maximum number of unique characters to a little over a
million. [^3] Unicode is divided into a disjoint ranges called “blocks”, which
usually group characters by script or language. Blocks are released over time
as the Unicode standard evolves.

[^3]: [How many characters can be mapped with Unicode?](https://stackoverflow.com/a/5924195)

In 1992, the Unicode consortium released an initial CJK[^4] block, titled
[CJK Unified Ideographs](https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)).
This block contains around 20, 000 code points representing common CJK
characters. Unicode continues to release “extension” blocks containing
less-common characters; these blocks are named 
[CJK Unified Ideographs Extension A](https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_Extension_A), 
[CJK Unified Ideographs Extension B](https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_Extension_B), etc. and act as supplements to the original
20, 000 characters. Later unified ideographic extension blocks contain CJK
characters of increasing rarity.

[^4]: In Unicode, characters which are used across many East Asian languages
      are broadly termed CJK, which stands for Chinese-Japanese-Korean.

As of 2020, there are around 93, 000[^5] CJK unified ideographs. Around two-thirds
of all the code points in Unicode are reserved for CJK characters.[^6]

[^5]: See [https://en.wikipedia.org/wiki/CJK_Unified_Ideographs](https://en.wikipedia.org/wiki/CJK_Unified_Ideographs).
[^6]: See [https://www.unicode.org/faq/han_cjk.html#16](https://www.unicode.org/faq/han_cjk.html#16).

#### Kangxi radicals and Unicode

Even though Unicode aims to encompass most CJK characters, there will always
be rare characters such as place names and proper nouns which do not appear
in Unicode. Unicode presents a simplistic compositional model for
representing rare characters. This compositional model consists of radicals
and composition actions:

* [Kangxi radicals block](https://en.wikipedia.org/wiki/Kangxi_radical#Kangxi_Radicals_block) is a Unicode block with code points for each of the 214 kangxi radicals. (Example: ⼀, ⼁, ⼂, ⼃, ⼄, …)
 
* [Ideographic Description Characters](https://en.wikipedia.org/wiki/Ideographic_Description_Characters_(Unicode_block)) is a Unicode block with code points for many common composition patterns. (Example: ⿰, ⿱, ⿲, ⿳, ⿴, …) Sequences of characters combined by ideographic description characters are known as ideographic description sequences. An ideographic sequence in Unicode consists of a series of code points, but a font may choose to render this sequence as a “shaped” glyph.

Thus a character like 好 can be written as ⿰女子. But on my platform, and likely on your platform, this sequence appears as three glyphs rather than as the single character 好 it represents. 

#### Why doesn’t the Unicode standard adopt a compositional model for encoding Han ideographs? Wouldn’t that save a large number of code points? 

In short, Unicode decided that the burden on font authors and the difficulty
of “normalization”, i.e. transforming characters into a normalized form to
allow for searching and comparison, was too great. For a more detailed
answer, see 
[the original question and answer](http://www.unicode.org/faq/han_cjk.html#16)
from the Unicode CJK FAQs.

#### Ideographic description sequence shaping

Since Unicode prefers individual code points over composition, fonts and the
platforms which enable them (Opentype, Truetype, etc.) generally choose to
not implement “ideographic description sequence shaping”, i.e. the process of
rendering “⿰女子” as “好”. Instead we rely on Unicode to pick the most common
characters, and on font authors to render those characters.

### Complications of CJK Font Rendering

Since modern text encoding for CJK characters is non-compositional, font
authors need to create a rendering for each individual character in question.
As noted above, there are around 93, 000 CJK unified ideographs. Due to the
number of characters and the difficulty of researching and creating faithful
renderings, most fonts lag the latest Unicode releases by several years. [^7]

[^7]: See [https://github.com/googlefonts/noto-cjk/issues/13](https://github.com/googlefonts/noto-cjk/issues/13) 
      and [https://github.com/adobe-fonts/source-han-sans/issues/222](https://github.com/adobe-fonts/source-han-sans/issues/222).


Why? It turns out that radical composition as described above has dozens of
complications, many of them aesthetic byproducts of the way natural
handwriting works: adjacent strokes get joined, complex radicals demand more
space than simple ones, and common, complex radicals get simplified. These
complications are natural to handwriting, but difficult to account for
algorithmically.

Here are some examples of complications:

#### Complication 1: Variable-proportion radicals

When a component is made of two or more radicals, those radicals will often
change proportion. These changes occur in response to the relative density of
the component radicals, although “relative density” is an inexact term.

Examples:

* When the left component of a character is less dense than the right
  component, the right component will take up around ⅔ of the horizontal space.
  (讠+ 吾 = 语).

* When the left and right components of a character are of equal density, each
  component will take up around ½ of the horizontal space (身 + 朵 = 躲).

* When the left and right components of a character are the same, each
  component will take up around ½ of the horizontal space (月 + 月 = 朋).

* When the top and bottom components of a character are the same shape, they
  will often “nest”. (Example: 夕 + 夕 = 多) This makes the proportions of the
  character closer to square.
  
These are just a few of [dozens of rough
guidelines](https://www.writtenchinese.com/how-to-make-sure-your-chinese-characters-are-balanced/), 
each with exceptions. Radicals can be squashed, stretched, scaled, and
translated (although never rotated) during composition.

The exact proportions and placement of radicals is not regular and should not
be thought of as algorithmic.

#### Complication 2: Variable-shape radicals

Often radicals will change shape as well as proportion when composed.

* When 刀 appears on the right, it can be written as刂 (as in 刖).
  (Counterexample: 切.) 
* When 人 appears on the left, it can be written as 亻(as in 他). (Counterexample:
  从.)
* When 手 appears on the left, it can be written as 扌(as in 扡). (Counterexample:
  拜, or 帮.)
* When 心 appears on the left, it can be written as 忄(as in 快).
* When 水 appears on the left, it can be written as 氵(as in 池).
* When 火 appears on the bottom, it can be written as 灬 (as in 黑).
* When 犬 appears on the left, it can be written as 犭(as in 猪).

These are just a few examples from a longer list. Like “i before e except
after c”, these rules tend to have as many exceptions as they do examples.

The final shape of a radical in an ideographic description sequence cannot be
algorithmically inferred from the original shape of that radical. It would be
incorrect to interpret (⿱占火 = 点); one would need to write (⿱占灬 = 点).

### The Long Tail

There is a long tail of characters in the CJK Unified Ideographic Extension
blocks which (a) have a Unicode representation, but (b) don’t yet have a
rendering in most fonts. A font which fails to implement CJK Unified
Ideographic Extension blocks B through G is missing roughly 65,000
characters. [^8] This gulf is approximately the difference between a standard
Chinese dictionary and a “complete” Chinese dictionary. These characters are
disproportionately likely to be proper nouns, place names, and other rare
characters.

[^8]: The characters in these extension blocks are unevenly distributed across
      traditional and simplified Chinese scripts as well as Japanese, Korean,
      Vietnamese, and other East Asian scripts.

## Work

I wrote and published a GAN which can predict what CJK characters should look
like. These predictions take the form of low-resolution raster images, which
are obviously unsuitable for use in fonts but might be a useful input for a
font design tool. (More to come on that later.)

### GANs

AutoCJK is no more complex than an adaptation of
[Pix2Pix](https://phillipi.github.io/pix2pix/), which I learned of from the
[Tensorflow Core Tutorials
site](https://www.tensorflow.org/tutorials/generative/pix2pix). Pix2Pix is a
[GAN](https://en.wikipedia.org/wiki/Generative_adversarial_network), i.e. a
generative adversarial network. In a GAN, two neural networks train to fool
each other: one network trains to produce accurate, realistic examples of
whatever in order to fool the discriminator, which trains to more accurately
discriminate between real elements and the generated examples.

GANs are often used on images, and are often used to generate fake faces. 

### Faces

Thinking about [faces](https://en.wikipedia.org/wiki/Face) actually
led me to the approach of using a GAN. Faces and CJK characters are similar
in a few ways: both are roughly optically balanced, both are easily
recognizable, and both have both macro and micro details which contribute
heavily to their apparent realism. When it comes to computationally
generating new faces, even a small mistake can betray an image as being
inauthentic.

In short, faces and CJK characters both seem to follow subtle rules which
don't cleanly fit into an 
[imperative algorithm](https://en.wikipedia.org/wiki/Imperative_programming) 
but which nonetheless can be generally predicted.

### Training Data

I fed this GAN training data[^9] where each input/output pair looked like
this:

![U+3416](https://raw.githubusercontent.com/google/autocjk/main/docs/images/0000022.png)

[^9]: You can generate training data like it with 
      [`make_dataset.py`](https://github.com/google/autocjk/blob/main/src/make_dataset.py)
      and some local fonts of your own.

I refitted the Pix2Pix
[tutorial](https://www.tensorflow.org/tutorials/generative/pix2pix) to accept
a 256x256x2 input tensor and predict a 256x256x1 output tensor.

* The input tensor was two 256x256 greyscale bitmaps of the full-width input
  characters. In the example above, picture the superposition of the first two
  thirds of the image, i.e. the segments containing `吉` and `乚`. By
  "superposition" I just mean that there were two layers to the image. You can
  picture this as red/green channels, if you like.

* The output tensor was one 256x256 greyscale bitmap of the full-width output
  character. In the example above, picture the left third of the image,
  containing `㐖`.

The vast majority of the Pix2Pix model was unchanged in [my
model](https://github.com/google/autocjk/blob/main/src/model.py).

### Training

I trained this model on [TPUs](https://cloud.google.com/tpu). You can train
this model (or one like it) on Google Cloud. You could also train this model
on a regular GPU or CPU.

### Model

The model [currently published](https://github.com/google/autocjk/blob/main/models/generator.h5)
as a part of [https://github.com/google/autocjk](https://github.com/google/autocjk)
was trained for around 48 hours. 

This model is definitely not perfect. The rasters it generates have rough
edges, and the proportions and kerning between the components are biased
towards the styles of the fonts I trained it on. (In this case, `zh-CN`.)
Over time I will revisit this model and experiment with loss functions,
higher and lower resolution predictions etc.

The model was trained on a large number of [Noto
CJK](https://www.google.com/get/noto/help/cjk/) fonts, but is by no means
limited to predicting outputs given inputs from that particular font. A large
part of my development cycle was
[cachebusting](https://en.wikipedia.org/wiki/Out-of-bag_error), i.e. testing
prediction on a set of inputs not in my training data.

In some cases this meant character pairs not in my
training data, but in other cases this meant fonts not in my training data.
My [thumbnail image](https://raw.githubusercontent.com/google/autocjk/main/docs/images/0x134772.png)
is actually trained from glyphs downloaded from
[GlyphWiki](https://glyphwiki.org).

## Usage

Prerequisites: install `git` and [`bazel`](https://bazel.build/).

Also a prerequisite: find a local font to draw input from. For example, if
you want to render `⿰市來`, you will first need a font which has renderings of
`市` and `來`. You could use [Noto CJK](https://www.google.com/get/noto/help/cjk/) 
for this, but if you do end up using another font, please let me know how it goes.

```bash
# Download the repo
git clone git@github.com:google/autocjk.git
# Run the generator
bazel run //src:main -- \
  --font_path=<path_to_font> \
  --lhs='市' \
  --rhs='來' \
  --out=/tmp/out.png
```

More feature work will follow. 

Please take out PRs and/or issues against
[https://github.com/google/autocjk](https://github.com/google/autocjk) if you
have questions or complaints.


## Other

I would be remiss if I didn't mention 
[Andrew West (魏安)](https://www.babelstone.co.uk/)'s 
[`IDS.TXT`](https://www.babelstone.co.uk/CJK/IDS.TXT), which currently offers
per-character decomposition for all 92,856 CJK unified ideographs defined in
Unicode version 13.0. This extraordinary resource powers the character
de/composition algorithm which underlies the training image generation
utility.

I would also be remiss if I didn't mention the numerous people inside Google
who helped me with this project in ways large and small.